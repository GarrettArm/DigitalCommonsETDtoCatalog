{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import copy\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_workbook(file):\n",
    "    print(file)\n",
    "    wb = openpyxl.load_workbook(file)\n",
    "    current_sheet = wb['1']\n",
    "    sheet_dict = dict()\n",
    "    for num, row in enumerate(current_sheet.iter_rows()):\n",
    "        if num == 0:\n",
    "            keys = [i.value or num for i in row]\n",
    "            continue\n",
    "        values = [i.value for i in row]\n",
    "        row_dict = {keys[i]: values[i] for i in range(len(keys))}\n",
    "        sheet_dict[num] = row_dict\n",
    "    return sheet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ediss = parse_workbook('ListBibliographyReport-EDISS-ETHESIS.xlsx')\n",
    "ediss_url = parse_workbook('URLreports-EDISS-ETHESIS.xlsx')\n",
    "diss = parse_workbook('ListBibliographyReport-DISS-THESIS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example digital commons items\n",
    "\n",
    "# print('ediss')\n",
    "# for row, value_dict in ediss.items():\n",
    "#     print(row, value_dict)\n",
    "#     break\n",
    "# print('ediss_url')\n",
    "# for row, value_dict in ediss_url.items():\n",
    "#     print(row, value_dict)\n",
    "#     break\n",
    "# print('diss')\n",
    "# for row, value_dict in diss.items():\n",
    "#     print(row, value_dict)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes duplicate rows if they are identical -- complains otherwise\n",
    "\n",
    "def remove_duplicate_rows(workbook):\n",
    "    print('starting length: {}'.format(len(workbook)))\n",
    "    squashed_workbook = dict()\n",
    "    for column, column_values in workbook.items():\n",
    "        flex_key = column_values.get('flexkey')\n",
    "        if flex_key in squashed_workbook:\n",
    "            for header, field_value in column_values.items():\n",
    "                if header in ('callnum', 'itemid', 'homeloca', 'currentloca', 'itemtype', 'library', 'Staff', 'permortemp', ):\n",
    "                    continue\n",
    "                if header in ('Suffix', 'Public', 'category3', 'category2', 'category1', 'CircNote', ):\n",
    "                    continue\n",
    "                if squashed_workbook[flex_key][header] != field_value:\n",
    "                    print('mismatched duplicated flexkeys {} {}'.format(flex_key, header))\n",
    "        else:\n",
    "            squashed_workbook[flex_key] = column_values\n",
    "    print('ending length: {}'.format(len(squashed_workbook)))\n",
    "    return squashed_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ediss_url = remove_duplicate_rows(ediss_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ediss = remove_duplicate_rows(ediss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no headers in common between two dicts before we merge them\n",
    "\n",
    "for flexkey, item_dict in ediss_url.items():\n",
    "    for header, value in item_dict.items():\n",
    "        if header in ('flexkey', ):\n",
    "            continue\n",
    "        if header in ediss.get(flexkey):\n",
    "            print('duplicate headers {} {}'.format(flexkey, header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dicts\n",
    "\n",
    "for flexkey, item_dict in ediss.items():\n",
    "    ediss[flexkey] = {**item_dict, **ediss_url[flexkey]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_duplicate_rows(diss)\n",
    "\n",
    "print('take home message:  there are a few different items with the same flexkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(*dicts):\n",
    "    counter = 0\n",
    "    merged_dict = dict()\n",
    "    for d in dicts:\n",
    "        for _, i in d.items():\n",
    "            try:\n",
    "                itemid = i['itemid']\n",
    "            except KeyError:\n",
    "                itemid = i['urn']\n",
    "            if not itemid:\n",
    "                merged_dict[counter] = i\n",
    "                counter += 1\n",
    "            elif itemid in merged_dict:\n",
    "                print(i)\n",
    "                print('duplicate {}'.format(itemid))\n",
    "                break\n",
    "            else:\n",
    "                merged_dict[itemid] = i\n",
    "    return merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_catalog = merge_dicts(ediss, diss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example merged_catalog item\n",
    "\n",
    "# for k, v in merged_catalog.items():\n",
    "#     for label, value in v.items():\n",
    "#         print(\"{}***  {}\".format(label, value))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digcomm_diss = parse_workbook('DigCommExports/gradschool_dissertations_1.xls_Fri_Mar_23_13_38_07_2018part_1.xlsx')\n",
    "# digcomm_historical = parse_workbook('DigCommExports/gradschool_disstheses_1.xls_Mon_Feb_26_11_28_15_2018part_1.xlsx')\n",
    "digcomm_majorp = parse_workbook('DigCommExports/gradschool_majorpapers_1.xls_Mon_Feb_26_11_25_49_2018part_1.xlsx')\n",
    "digcomm_thess = parse_workbook('DigCommExports/gradschool_theses_1.xls_Mon_Apr_30_09_40_49_2018part_1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_digcomm = merge_dicts(digcomm_majorp, digcomm_thess, digcomm_diss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example merged_digcomm item\n",
    "\n",
    "# for k, v in merged_digcomm.items():\n",
    "#     for label, value in v.items():\n",
    "#         print(\"{}***  {}\".format(label, value))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if urn already in catalog, remove the item from merged_digcomm\n",
    "\n",
    "print(len(merged_digcomm))\n",
    "for k, v in merged_catalog.items():\n",
    "    urn = v.get('Subfield u of 856')\n",
    "    if not urn:\n",
    "        continue\n",
    "    urn = urn.replace('http://digitalcommons.lsu.edu/do/search/?q=', '').replace('/', '')\n",
    "    if urn in merged_digcomm:\n",
    "        merged_digcomm.pop(urn)\n",
    "print(len(merged_digcomm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(digcomm_historical))\n",
    "# for k, v in merged_catalog.items():\n",
    "#     urn = v.get('Subfield u of 856')\n",
    "#     if not urn:\n",
    "#         continue\n",
    "#     urn = urn.replace('http://digitalcommons.lsu.edu/do/search/?q=', '').replace('/', '')\n",
    "#     if urn in digcomm_historical:\n",
    "#         digcomm_historical.pop(urn)\n",
    "# print(len(digcomm_historical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_for_author_match(author_f, author_m, author_l):\n",
    "    return [item_dict for urn, item_dict in merged_catalog.items()\n",
    "        if '{}, {} {}'.format(author_l, author_f, author_m).lower() in item_dict.get('author', '').lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alnum_string(string):\n",
    "    return ''.join([i.lower() for i in string if i.isalnum()]).replace('carbon', 'c').replace('beta', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(item_dict):\n",
    "    title, year = item_dict.get('title'), item_dict.get('publication_date')\n",
    "    full_author = '{} {} {} {}'.format(item_dict.get('author1_fname', ''),\n",
    "                                  item_dict.get('author1_mname', ''),\n",
    "                                  item_dict.get('author1_lname', ''),\n",
    "                                  item_dict.get('author1_suffix', ''))\n",
    "    author_last = item_dict.get('author1_lname', '')\n",
    "    author_first = item_dict.get('author1_fname', '')\n",
    "    author_middle = item_dict.get('author1_mname', '')\n",
    "    return title, full_author, author_last, author_first, author_middle, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash_flatten(string):\n",
    "    return ''.join(\n",
    "        [i.lower() for i in string.replace('(Spanish Text)', '')\n",
    "         if (64 < ord(i) < 90) or (96 < ord(i) < 123)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_in(str_a, str_b):\n",
    "    list_a = [i for i in squash_flatten(str_a)]\n",
    "    list_b = [i for i in squash_flatten(str_b)]\n",
    "    new_list_a = list_a[:]\n",
    "    new_list_b = list_b[:]\n",
    "    for char in list_a:\n",
    "        try:\n",
    "            new_list_b.remove(char)\n",
    "        except:\n",
    "            pass\n",
    "    for char in list_b:\n",
    "        try:\n",
    "            new_list_a.remove(char)\n",
    "        except:\n",
    "            pass\n",
    "    return ''.join(new_list_a), ''.join(new_list_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reck(string, author):\n",
    "    return squash_flatten(string.replace('[electronic resource]', '').replace(f'{author}', '').split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If confirmed no match, record sent to manual_checked_no_match.\n",
    "# If confirmed match, record popped.\n",
    "\n",
    "\n",
    "def purge_matches(digcomm, catalog):\n",
    "    digcomm_copy = copy.deepcopy(digcomm)\n",
    "    print(len(digcomm_copy))\n",
    "    digcomm_copy = {k: v for k, v in digcomm_copy.items() if v['publication_date'].year < 2014}\n",
    "    print(len(digcomm_copy))\n",
    "    for urn, item_dict in digcomm_copy.items():\n",
    "        title, full_author, author_last, author_first, author_middle, year = get_info(item_dict)\n",
    "        full_author = ' '.join([i for i in full_author.split(' ') if i != 'None'])\n",
    "        digcomm_date = item_dict['publication_date'].year\n",
    "        potential_matches = look_for_author_match(author_first, author_middle, author_last)\n",
    "#         if not potential_matches:\n",
    "#             print('{}, {} {}'.format(author_last, author_first, author_middle))\n",
    "#         print('{} potential matches'.format(len(potential_matches)))\n",
    "        for p in potential_matches:\n",
    "            min_range, max_range = p['pubyr'] - 5, p['pubyr'] + 5\n",
    "#             if (min_range > digcomm_date) or (max_range < digcomm_date):\n",
    "#                 continue\n",
    "            print(title)\n",
    "            print(p.get('title'))\n",
    "            print('\\n')\n",
    "#             if reck(p.get('title'), full_author) == reck(title, full_author):\n",
    "#                 merged_digcomm.pop(urn)\n",
    "#                 break\n",
    "#             if alnum_string(p.get('title')) == alnum_string(title):\n",
    "#                 digcomm_historical.pop(urn)\n",
    "#                 break\n",
    "#             if squash_flatten(p.get('title')) == squash_flatten(title):\n",
    "#                 digcomm_historical.pop(urn)\n",
    "#                 break\n",
    "#             diff_a, diff_b = difference_in(p.get('title'), title)\n",
    "#             if len(diff_a) < 3 and len(diff_b) < 4:\n",
    "#                 digcomm_historical.pop(urn)\n",
    "#                 break\n",
    "#             p_last_name, p_first_parts, *args = p.get('author').split(',')\n",
    "#             p_first_name, p_middle_name, *args = p_first_parts.strip().split(' ')\n",
    "#             reshaped_p_author = 'by{}{}{}'.format(p_first_name, p_middle_name, p_last_name).lower()\n",
    "#             if alnum_string(p.get('title')).replace(reshaped_p_author, '') == alnum_string(title):\n",
    "#                 digcomm_historical.pop(urn)\n",
    "#                 break\n",
    "#             difference_a, difference_b = difference_in(p.get('title'),\n",
    "#                                                        title)\n",
    "\n",
    "#             print('{}\\n{}\\n{}\\n### {}\\n'.format(title, full_author, year, difference_b))\n",
    "#             print('{}\\n{}\\n{}\\n### {}\\n'.format(p.get('title', ''),\n",
    "#                                         p.get('author', ''),\n",
    "#                                         p.get('pubyr', ''),\n",
    "#                                         difference_a))\n",
    "\n",
    "            response = input('are these the same? (y/n)')\n",
    "            if response.lower().strip() == 'y':          \n",
    "                merged_digcomm.pop(urn)\n",
    "                break\n",
    "#             if response.lower().strip() == 'skip':\n",
    "#                 break\n",
    "#         else:\n",
    "#             manual_checked_no_matches[urn] = item_dict\n",
    "#             digcomm_historical.pop(urn)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge_matches(merged_digcomm, merged_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_digcomm), len(merged_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reck(\"\"\"EM Algorithm for Multiple Wideband Source Localization\"\"\", 'Kiran Kumar Mada'))\n",
    "print(reck(\"\"\"EM algorithm for multiple wideband source localization [electronic resource] / by Kiran Kumar Mada\"\"\", 'Kiran Kumar Mada'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_dict_to_csv(output_filename, source_dict):\n",
    "    with open(output_filename, 'w') as f:\n",
    "        for urn, item_dict in source_dict.items():\n",
    "            headers = sorted(item_dict.keys())\n",
    "            break\n",
    "        w = csv.DictWriter(f, headers)\n",
    "        w.writeheader()\n",
    "        for urn, item_dict in source_dict.items():\n",
    "            w.writerow(item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict_to_csv('DigCommPossiblyNotInCatalog.csv', merged_digcomm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
